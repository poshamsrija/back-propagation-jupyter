# back-propagation-jupyter
Backpropagation is a supervised learning algorithm used to train artificial neural networks. It calculates the error at the output and propagates it backward through the network, adjusting weights and biases using gradient descent to minimize the loss and improve predictions.
# Backpropagation Neural Network

## Description
This Jupyter Notebook demonstrates **Backpropagation**, a core algorithm for training **artificial neural networks**. It calculates errors at the output, propagates them backward, and updates weights using **gradient descent** to minimize loss.

The notebook covers:
- Forward pass calculation
- Backward pass (error propagation)
- Weight and bias updates
- Making predictions

Backpropagation is used in **image recognition, speech processing, and other deep learning tasks**.



## How It Works
1. **Forward Pass**: Compute the output of the network.  
2. **Error Calculation**: Determine the difference between predicted and actual outputs.  
3. **Backward Pass**: Propagate errors backward and compute gradients.  
4. **Weight Update**: Adjust weights using gradient descent to reduce loss.



## Requirements
- Python 3.x
- Jupyter Notebook
- Libraries: `numpy`


## Usage
1. Open `backpropagation.ipynb` in Jupyter Notebook.
2. Run all cells to train the network and see predictions.
3. Modify inputs or network parameters to test different scenarios.


